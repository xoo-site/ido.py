#db_available
[[metric]]
metricName = "db_available_check"
groupName = "live"
metricLabels = ["conid" ]
metricDesc = { value= "Gauge metric with query from dual" }
scraperFlags=true
ignorezeroresult = false
metricGroup="/live"
request = "select 1 as value from dual"

#db_available for metrics path output
[[metric]]
metricName = "db_available_check_metrics"
groupName = "live"
metricLabels = ["conid" ]
metricDesc = { db_available_check= "Gauge metric with query from dual" }
useMetricDescKey=true
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics"
request = "select 1 as db_available_check from dual"

#db_uptime
[[metric]]
metricName = "db_uptime"
groupName = "uptime"
metricLabels = ["conid" ]
metricDesc = { value= "Gauge metric with oracle startup time from v$instance" }
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics"
request = "SELECT TO_NUMBER(sysdate - startup_time) * 24 * 60 * 60  as value FROM v$instance"

#db_status.status
[[metric]]
metricName = "db_status"
groupName = "dbStatus"
metricLabels = ["conid" ]
metricDesc = { value= "Gauge metric with the status of backup database from v$instance" }
useMetricDescKey=true
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics"
request = '''
select case
           when status = 'STARTED' then 1
           when status = 'MOUNTED' then 2
           when status = 'OPEN' then 3
           else 0 end as value
from v$instance
'''

#db_status.stb_rfs_health
[[metric]]
metricName = "stb_rfs_health"
groupName = "dbStatus"
metricLabels = ["conid", "thread_no" ]
metricDesc = { value= "Gauge metric with backup database standby rfs healthy from v$managed_standby" }
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics"
request = "select sum(BLOCK#) as value, thread# as thread_no from v$managed_standby where PROCESS='RFS' and thread# >0  group by THREAD#"

#db_status.active_status
[[metric]]
metricName = "active_status"
groupName = "dbStatus"
metricLabels = ["conid" ]
metricDesc = { value= "Gauge metric with backup database standby active log status from v$instance" }
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics"
request = "select count(*) as value from v$standby_log where STATUS = 'ACTIVE'"

#db_sys_time_model
[[metric]]
metricName = "db_sys_time_model"
groupName = "timeCpu"
metricLabels = ["conid" ]
metricDesc = { value= "Gauge metric with db time and cpu message from v$sys_time_model" }
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics"
fieldtoappend="stat_name"
ignoreMetricName=true
request = "select stat_name,Round(value/1000000) as value from v$sys_time_model where stat_name in ('DB time','DB CPU')"

#db_gap
[[metric]]
metricName = "archive_gap"
groupName = "gap"
metricLabels = ["conid" ]
metricDesc = { value="Generic counter metric from v$managed_standby " }
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics"
request = "select decode(count(*) ,0, 0, 1) as value from v$managed_standby where status='WAIT_FOR_GAP'"

#db_parameter
[[metric]]
metricName = "db_parameter"
groupName = "parameter"
metricLabels = ["conid" ]
metricDesc = { value="Gauge metric with sga_target and cpu_count from v$parameter " }
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics"
request = "select case when name = 'sga_target' then 'sga' else name end as name, value  from v$parameter where name in ('sga_target','cpu_count')"
fieldtoappend="name"
ignoreMetricName=true

#db_process
[[metric]]
metricName = "processes"
groupName = "processes"
metricLabels = ["conid" ]
metricDesc = {processes="Gauge metric with count of process from v$process ",pga_used_mem="Gauge metric with pga used memory from v$process ", pga_alloc_mem="Gauge metric with pga allocated memory from v$process " }
useMetricDescKey=true
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics"
request = "select count(*) as processes, sum(PGA_USED_MEM) as pga_used_mem, sum(PGA_ALLOC_MEM) as pga_alloc_mem from v$process"

#db_redo
[[metric]]
metricName = "db_redo"
groupName = "redo"
metricLabels = ["conid" ]
metricDesc = { value="Gauge metric with count of available redo message from v$log " }
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics"
request = "select count(*) as value from v$log where status in ('INACTIVE','UNUSED')"

#db_scheduler_job
[[metric]]
metricName = "scheduler_job"
groupName = "scheduler"
metricLabels = ["conid" ]
metricDesc = { value="Gauge metric with count of failed transaction from dba_scheduler_jobs " }
scraperFlags=true
ignorezeroresult = false
singleRecord=true #多行数据只处理一行
metricGroup="/metrics"
request = '''
select count(*) value from (select owner|| '.' || job_name as value from dba_scheduler_jobs where state = 'FAILED'
union all
select to_char(job) as value from dba_jobs where failures > 0 and broken='N')
'''

#db_latency
[[metric]]
metricName = "latency"
groupName = "latency"
metricLabels = ["conid" ]
metricDesc = { value="Gauge metric with transport lag and apply lag latency from v$dataguard_stats " }
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics"
ignoreMetricName=true
fieldtoappend="name"
rowFmtFunc={value="latencyTimeFmt"}
request = '''
select case
           when name = 'transport lag' then 'transport latency'
           when name = 'apply lag' then 'apply latency' end as name,
       value
from v$dataguard_stats
where name in ('transport lag', 'apply lag')
'''

#db_archived_log
[[metric]]
metricName = "db_archived_log"
groupName = "archive"
metricLabels = ["conid"]
metricDesc = { value="Gauge metric with capacity of archived log in one day message from v$archived_log " }
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics_log"
request = '''
SELECT SUM(BLOCKS * BLOCK_SIZE) / 1024 / 1024 as value, TO_CHAR(NEXT_TIME, 'yyyymmdd') as time
    FROM v$archived_log
    WHERE CREATOR in ('LGWR','ARCH')
	AND standby_dest='NO'
    AND first_time > SYSDATE - 7
    AND TO_CHAR(NEXT_TIME, 'yyyymmdd') = to_char(sysdate-1,'yyyymmdd')
    GROUP BY TO_CHAR(NEXT_TIME, 'yyyymmdd')
'''

#db_archived_log_hour
[[metric]]
metricName = "db_archived_log_hour"
groupName = "archiveHour"
metricLabels = ["conid"]
metricDesc = { value="Gauge metric with the capacity of archived log in the last hour from v$archived_log " }
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics_log"
request = '''
SELECT SUM(b.blocks * b.block_size) / 1024 / 1024 as value, TO_CHAR(a.next_time, 'yyyymmddhh24') as time
	FROM v$archived_log a, (SELECT MAX(blocks) blocks, MAX(block_size) block_size, sequence# FROM v$archived_log GROUP BY sequence#) b
	WHERE a.CREATOR in ('LGWR','ARCH')
	AND a.standby_dest = 'NO'
	AND a.sequence# = b.sequence#
	AND TO_CHAR(a.NEXT_TIME, 'yyyymmddhh24') = TO_CHAR(sysdate -1/24, 'yyyymmddhh24')
	GROUP BY TO_CHAR(a.NEXT_TIME, 'yyyymmddhh24')
'''

#db_asm
[[metric]]
metricName = "db_asm"
groupName = "asm"
metricLabels = ["conid","name"]
metricDesc = { db_asm_used="Gauge metric with ASM disk group used percent from v$asm_diskgroup ",db_asm_offline="Gauge metric with ASM disk group offline disk from v$asm_diskgroup "}
useMetricDescKey=true
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics_storage"
request = '''
select name, 100*(total_mb-free_mb)/total_mb as db_asm_used, offline_disks as db_asm_offline
from v$asm_diskgroup
where total_mb<>0 and state in ('MOUNTED','CONNECTED')
'''

#db_manage_standby.mrp0
#db_manage_standby.rfs
[[metric]]
metricName = "db_standby_process_status"
groupName = "managerStandby"
metricLabels = ["conid"]
metricDesc = { value="Gauge metric with standby mrp0 and rfs process status from v$managed_standby "}
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics"
fieldtoappend="name"
ignoreMetricName=true
request = '''
select 'mrp0' as name, decode(count(*) ,0, 0, 1) as value from v$managed_standby where process = 'MRP0'
union all
select 'rfs' as name, decode(count(*) ,0, 0, 1) as value from v$managed_standby where process = 'RFS'
'''

#db_manage_standby.stb_process
#important !!! 相同指标名的情况下, 指标描述[sequence_num,block_num]必须一致
[[metric]]
metricName = "stb_process"
groupName = "managerStandby"
metricLabels = ["conid", "thread", "val_type"]
metricDesc = { sequence_num="Gauge metric with standby sequence_number and block_number of mrp0 process from v$managed_standby ", block_num="Gauge metric with standby sequence_number and block_number of mrp0 process from v$managed_standby "}
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics"
constLabelValues = {"val_type"={sequence_num="sequence", block_num="block"}}
singleRecord=true #多行数据只处理一行
request = '''
select thread# as thread, sequence# as sequence_num, block# as block_num from v$managed_standby where process like 'MR%'
'''

#db_recovery
[[metric]]
metricName = "db_recovery"
groupName = "recovery"
metricLabels = ["conid" ]
metricDesc = { value= "Gauge metric with recovery metric from v$recovery_progress" }
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics"
IgnoreMetricName=true
fieldtoappend="item"
request = '''
select item, sofar as value from v$recovery_progress where start_time = (select max(start_time)
from v$recovery_progress)
and item in ('Active Apply Rate', 'Average Apply Rate', 'Apply Time per Log', 'Checkpoint Time per Log', 'Log Files', 'Maximum Apply Rate', 'Redo Applied', 'Active Time', 'Elapsed Time', 'Standby Apply Lag')
'''

#db_recovery.last_redo
[[metric]]
metricName = "db_recovery_last_redo"
groupName = "recovery"
subsystem = "last"
metricLabels = ["conid" ]
metricDesc = { applied_redo_sofar= "Gauge metric with last applied redo sofar value from v$recovery_progress", applied_redo_timestamp="Gauge metric with last applied redo timestamp from v$recovery_progress"}
useMetricDescKey=true
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics"
singleRecord=true #多行数据只处理一行
rowFmtFunc={applied_redo_timestamp="redoTimeFmt"}
request = '''
select item, sofar as applied_redo_sofar, to_char(timestamp, 'yyyy-mm-dd hh24:mi:ss') as applied_redo_timestamp
from v$recovery_progress
where start_time = (select max(start_time) from v$recovery_progress) and item = 'Last Applied Redo'
'''

#db_transaction
[[metric]]
metricName = "db_transaction"
groupName = "transaction"
metricLabels = ["conid" ]
metricDesc = { db_transaction_count= "Gauge metric with the number of transaction from v$transaction", db_max_blocks="Gauge metric with transaction max blocks from v$transaction", db_max_duration= "Gauge metric with transaction max duration from v$transaction"}
useMetricDescKey=true
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics"
request = '''
SELECT trans_cnt db_transaction_count,
    round(max_blocks * 1000, 2) as db_max_blocks,
    round(max_duaration, 0) as db_max_duration
FROM (select count(*) trans_cnt,
             nvl(max(used_ublk), 0) / 1000 max_blocks,
             nvl((sysdate - min(to_date(start_time, 'mm/dd/yy hh24:mi:ss'))),
                 0) * 1440 * 60 max_duaration
      FROM v$transaction)
'''

#db_undo
[[metric]]
metricName = "db_undo"
groupName = "undo"
metricLabels = ["conid" ]
metricDesc = { value= "Gauge metric with undo of use condition message from v$undostat"}
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics"
request = '''
select case
           when undo_percent >= 100 then 100
           when undo_percent is null then 0
           else undo_percent
           end value
from (
         select trunc(100 * (select sum(undoblks) * 8 * 1024 as undouse
                             from v$undostat
                             where begin_time >
                                   (sysdate -
                                    (select value / 60 / 60 / 24 from v$parameter where name = 'undo_retention'))) /
                      (select sum(bytes) as undosum
                       from dba_data_files
                       where tablespace_name in
                             (select upper(value)
                              from v$parameter
                              where name = 'undo_tablespace'))) as undo_percent
         from dual
     )
'''

#db_sysstat
[[metric]]
metricName = "db_sysstat"
groupName = "sysstat"
metricLabels = ["conid" ]
metricDesc = { value= "Gauge metric with db sysstat from v$sysstat" }
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics"
fieldtoappend="name"
ignoreMetricName=true
request = '''
select
       case
           when name = 'gc cr block receive time' then 'rac gc cr block receive time'
           when name = 'gc current block receive time' then 'rac gc current block receive time'
           when name = 'gc cr block send time' then 'rac gc cr block send time'
           when name = 'gc current block send time' then 'rac gc current block send time'

           when name = 'gc cr blocks received' then 'rac gc cr blocks received'
           when name = 'gc cr blocks served' then 'rac gc cr blocks served'
           when name = 'gc current blocks received' then 'rac gc current blocks received'
           when name = 'gc current blocks served' then 'rac gc current blocks served'
           else name
        end as name,
       case
           when name = 'gc cr block receive time' then value * 10
           when name = 'gc current block receive time' then value * 10
           when name = 'gc cr block send time' then value * 10
           when name = 'gc current block send time' then value * 10
           else value
        end as value
from v$sysstat
WHERE name IN
      ('execute count',
       'user commits',
       'session logical reads',
       'redo size',
       'redo writes',
       'parse count (hard)',
       'parse count (total)',
       'gc cr blocks received',
       'gc current blocks received',
       'gc cr blocks served',
       'gc current blocks served',
       'gc cr block receive time',
       'gc current block receive time',
       'gc cr block send time',
       'gc current block send time',
       'bytes sent via SQL*Net to client',
       'bytes received via SQL*Net from client',
       'physical read IO requests',
       'physical read bytes',
       'physical write IO requests',
       'physical write bytes')
'''

#db_session.user_active_session
[[metric]]
metricName = "user_active_session"
groupName = "session"
metricLabels = ["conid" ]
metricDesc = { aas= "Gauge metric with user active sessions from v$session",cpu_aas="Gauge metric with cpu aas from v$session", io_aas="Gauge metric with io aas from v$session", commit_aas="Gauge metric with commit aas from v$session", cluster_aas="Gauge metric with cluster aas from v$session", application_aas="Gauge metric with application aas from v$session", other_aas="Gauge metric with other aas from v$session"}
# 支持SQL alias 名称不能超过30个字符
aliasMetricKey = {aas = "user_active_sessions_aas", cpu_aas="user_active_sessions_cpu_aas", io_aas="user_active_sessions_io_aas", commit_aas="user_active_sessions_commit_aas", cluster_aas="user_active_sessions_cluster_aas", application_aas="user_active_sessions_appli_aas", other_aas="user_active_sessions_other_aas"}
useMetricDescKey=true
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics"
singleRecord=true #多行数据只处理一行
request = '''
SELECT COUNT (*) aas,
       SUM (CASE WHEN state != 'WAITING' THEN 1 ELSE 0 END) cpu_aas,
       SUM (CASE WHEN state = 'WAITING' and wait_class = 'User I/O' THEN 1 ELSE 0 END) io_aas,
       SUM (CASE WHEN state = 'WAITING' and wait_class = 'Commit' THEN 1 ELSE 0 END) commit_aas,
       SUM (CASE WHEN state = 'WAITING' and wait_class = 'Cluster' THEN 1 ELSE 0 END) cluster_aas,
       SUM (CASE WHEN state = 'WAITING' and wait_class = 'Application' THEN 1 ELSE 0 END) application_aas,
       COUNT (*)
       - SUM (CASE WHEN state != 'WAITING' THEN 1 ELSE 0 END)
       - SUM (CASE WHEN state = 'WAITING' and wait_class = 'User I/O' THEN 1 ELSE 0 END)
       - SUM (CASE WHEN state = 'WAITING' and wait_class = 'Commit' THEN 1 ELSE 0 END)
       - SUM (CASE WHEN state = 'WAITING' and wait_class = 'Cluster' THEN 1 ELSE 0 END)
       - SUM (CASE WHEN state = 'WAITING' and wait_class = 'Application' THEN 1 ELSE 0 END)
          other_aas
  FROM v$session a
 WHERE a.status = 'ACTIVE' AND a.TYPE = 'USER' AND (a.wait_class != 'Idle')
'''

#db_session.blocking_session
[[metric]]
metricName = "blocking_session"
groupName = "session"
metricLabels = ["conid" ]
metricDesc = { value= "Gauge metric with number of blocking sessions from v$session"}
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics"
singleRecord=true #多行数据只处理一行
request = '''
SELECT count(*) value
FROM (SELECT
          sid,
          username,
          serial#,
          status,
          process,
          NVL(sql_id, 0),
          sql_address,
          blocking_session,
          wait_class,
          event,
          p1,
          p2,
          p3,
          seconds_in_wait
      FROM v$session
      WHERE blocking_session_status = 'VALID'
      )
'''

# db_system_event
[[metric]]
metricName = "db_system_event"
groupName = "systemEvent"
metricLabels = ["conid"]
metricDesc = { total_waits= "Gauge metric with total waits and time waited system event from v$system_event", time_waited="Gauge metric with total waits and time waited system event from v$system_event"}
useMetricDescKey=true
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics"
fieldtoappend="event"
request = '''
select case when event = 'log file switch (checkpoint incomplete)' then 'log file switch' else event end event, total_waits, time_waited * 10 time_waited from (
select event, max(total_waits) total_waits, max(time_waited)  time_waited from (
(select 'db file sequential read' as event, 0 as total_waits, 0 as time_waited from dual union
select 'db file scattered read' as event, 0 as total_waits, 0 as time_waited from dual union
select 'log file sync' as event, 0 as total_waits, 0 as time_waited from dual union
select 'log file parallel write' as event, 0 as total_waits, 0 as time_waited from dual union
select 'direct path read' as event, 0 as total_waits, 0 as time_waited from dual union
select 'direct path write' as event, 0 as total_waits, 0 as time_waited from dual union
select 'log file switch (checkpoint incomplete)' as event, 0 as total_waits, 0 as time_waited from dual) union
select event, total_waits, time_waited
from v$system_event
where event IN
      ('db file sequential read',
       'db file scattered read',
       'log file sync',
       'log file parallel write',
       'direct path read',
       'direct path write',
       'log file switch (checkpoint incomplete)'))  group by event)
'''

# db_tablespace.dba_history_tablespace
# UNDO类型的表空间无法计算使用率，但可以查到已经使用大小
[[metric]]
metricName = "dba_history_tablespace"
groupName = "tablespace"
metricLabels = ["conid", "tablespacename"]
metricDesc = { histablespace_current_size= "Gauge metric with current size from DBA_HIST_TBSPC_SPACE_USAGE, v$tablespace, dba_tablespaces", histablespace_free_size="Gauge metric with free size from DBA_HIST_TBSPC_SPACE_USAGE, v$tablespace, dba_tablespaces", histablespace_used_size="Gauge metric with used size from DBA_HIST_TBSPC_SPACE_USAGE, v$tablespace, dba_tablespaces"}
useMetricDescKey=true
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics_storage"
request = '''
SELECT a.snap_id,
       b.tablespace_name as tablespacename,
       (a.tablespace_size * b.block_size)     histablespace_current_size,
       (((a.TABLESPACE_MAXSIZE * b.block_size))
           - ((a.tablespace_usedsize * b.block_size))) histablespace_free_size,
       (a.tablespace_usedsize * b.block_size) histablespace_used_size
FROM DBA_HIST_TBSPC_SPACE_USAGE a,
     v$tablespace d,
     dba_tablespaces b
WHERE a.TABLESPACE_ID = d.ts#
AND a.snap_id >= (select max(snap_id) from DBA_HIST_TBSPC_SPACE_USAGE)
AND d.name = b.tablespace_name
'''

# db_tablespace.dba_tablespace
[[metric]]
metricName = "dba_tablespace"
groupName = "tablespace"
metricLabels = ["conid", "tablespacename"]
metricDesc = { dba_tablespace_used_percent= "Gauge metric with maximum percent of available tablespace from dba_tablespaces, dba_data_files", dba_tablespace_free_size="Gauge metric with free size from dba_tablespaces, dba_data_files", dba_tablespace_used_pct_now="Gauge metric with current already used ratio of tablespace from dba_tablespaces, dba_data_files"}
aliasMetricKey = {dba_tablespace_used_pct_now = "dba_tablespace_used_percent_now"}
useMetricDescKey=true
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics_storage"
request = '''
WITH df AS
 (SELECT tablespace_name,
         SUM(bytes) bytes,
         sum(decode(autoextensible,
                    'YES',
                    decode(sign(maxbytes - bytes),
                           '1',
                           trunc(maxbytes),
                           '-1',
                           trunc(bytes),
                           '0',
                           trunc(maxbytes)),
                    'NO',
                    trunc(bytes))) as total_bytes,
         COUNT(*) cnt,
         DECODE(SUM(DECODE(autoextensible, 'NO', 0, 1)), 0, 'NO', 'YES') autoext
    FROM dba_data_files
   GROUP BY tablespace_name),
um AS
 (SELECT tablespace_name, used_space ub, used_percent
    FROM dba_tablespace_usage_metrics)
SELECT d.tablespace_name tablespacename,
       round(NVL((a.bytes - NVL(f.bytes, 0)) / a.bytes * 100, 0), 2) dba_tablespace_used_pct_now,
       round(NVL(a.bytes, 0), 2) ,
       round(u.used_percent, 2) dba_tablespace_used_percent,
       round(NVL(a.total_bytes, 2)) tab_max_size,
       a.total_bytes-a.total_bytes*0.01*u.used_percent dba_tablespace_free_size,
       a.autoext,
       round(NVL(a.bytes - NVL(f.bytes, 0), 0), 4),
       round(NVL(f.bytes, 0), 4),
       d.status,
       a.cnt,
       d.contents,
       d.extent_management,
       d.segment_space_management
  FROM dba_tablespaces d,
       df a,
       um u,
       (SELECT tablespace_name, SUM(bytes) bytes
          FROM dba_free_space
         GROUP BY tablespace_name) f
 WHERE d.tablespace_name = a.tablespace_name(+)
   AND d.tablespace_name = f.tablespace_name(+)
   AND d.tablespace_name = u.tablespace_name(+)
   AND NOT d.contents = 'UNDO'
   AND NOT (d.extent_management = 'LOCAL' AND d.contents = 'TEMPORARY')
UNION ALL
SELECT d.tablespace_name,
       round(NVL((u.ub * d.block_size) / tf.bytes * 100, 0), 2),
       round(NVL(tf.bytes, 0), 2),
       round(u.used_percent, 2),
       round(NVL(tf.total_bytes, 2)),
       tf.total_bytes-tf.total_bytes*0.01*u.used_percent dba_tablespace_free_size,
       tf.autoext,
       round(NVL(u.ub * d.block_size, 0), 4) dd,
       round((NVL(tf.bytes, 0) - NVL(u.ub * d.block_size, 0)), 4),
       d.status,
       tf.cnt,
       d.contents,
       d.extent_management,
       d.segment_space_management
  FROM dba_tablespaces d,
       um u,
       (SELECT tablespace_name,
               SUM(bytes) bytes,
               sum(decode(autoextensible,
                          'YES',
                          decode(sign(maxbytes - bytes),
                                 '1',
                                 trunc(maxbytes),
                                 '-1',
                                 trunc(bytes),
                                 '0',
                                 trunc(maxbytes)),
                          'NO',
                          trunc(bytes))) as total_bytes,
               COUNT(*) cnt,
               DECODE(SUM(DECODE(autoextensible, 'NO', 0, 1)),
                      0,
                      'NO',
                      'YES') autoext
          FROM dba_temp_files
         GROUP BY tablespace_name) tf
 WHERE d.tablespace_name = tf.tablespace_name(+)
   AND d.tablespace_name = u.tablespace_name(+)
   AND d.extent_management = 'LOCAL'
   AND d.contents = 'TEMPORARY'
'''

#db_available for metrics_storage path output
[[metric]]
metricName = "db_available_check_storage"
groupName = "tablespace"
metricLabels = ["conid" ]
metricDesc = { db_available_check= "Gauge metric with query from dual" }
useMetricDescKey=true
scraperFlags=true
ignorezeroresult = false
metricGroup="/metrics_storage"
request = "select 1 as db_available_check from dual"
